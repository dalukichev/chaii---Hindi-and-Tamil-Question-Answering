{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0d2360",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:24.384356Z",
          "iopub.status.busy": "2021-09-27T15:04:24.383526Z",
          "iopub.status.idle": "2021-09-27T15:04:32.423076Z",
          "shell.execute_reply": "2021-09-27T15:04:32.422191Z"
        },
        "papermill": {
          "duration": 8.058766,
          "end_time": "2021-09-27T15:04:32.423204",
          "exception": false,
          "start_time": "2021-09-27T15:04:24.364438",
          "status": "completed"
        },
        "tags": [],
        "id": "1c0d2360"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from functools import partial\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from datasets import Dataset\n",
        "from accelerate import Accelerator\n",
        "from transformers import (AutoTokenizer, AutoModelForQuestionAnswering,AutoModel,\n",
        "                          AutoConfig,AdamW,get_linear_schedule_with_warmup,\n",
        "                          get_cosine_schedule_with_warmup)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Конфигурации модели"
      ],
      "metadata": {
        "id": "vkOyjr0LWR1n"
      },
      "id": "vkOyjr0LWR1n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9419fd8d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:32.452352Z",
          "iopub.status.busy": "2021-09-27T15:04:32.451834Z",
          "iopub.status.idle": "2021-09-27T15:04:32.458595Z",
          "shell.execute_reply": "2021-09-27T15:04:32.458123Z"
        },
        "papermill": {
          "duration": 0.024545,
          "end_time": "2021-09-27T15:04:32.458701",
          "exception": false,
          "start_time": "2021-09-27T15:04:32.434156",
          "status": "completed"
        },
        "tags": [],
        "id": "9419fd8d"
      },
      "outputs": [],
      "source": [
        "config = {'model_path':'../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2',\n",
        "          \n",
        "          'max_length':384,\n",
        "          'doc_stride':128,\n",
        "          'max_answer_length':30,\n",
        "          \n",
        "          'lr':1e-5,\n",
        "          'wd':1e-2,\n",
        "    \n",
        "          'epochs':1,\n",
        "          'nfolds':5,\n",
        "          'batch_size':4,\n",
        "          'num_workers':4,\n",
        "          'seed':1000}\n",
        "\n",
        "for i in range(config['nfolds']):\n",
        "    os.makedirs(f'model{i}',exist_ok=True)\n",
        "    \n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONASSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(seed=config['seed'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных"
      ],
      "metadata": {
        "id": "bXHSZUgYWa5S"
      },
      "id": "bXHSZUgYWa5S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2a1858",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:32.486948Z",
          "iopub.status.busy": "2021-09-27T15:04:32.486437Z",
          "iopub.status.idle": "2021-09-27T15:04:33.704747Z",
          "shell.execute_reply": "2021-09-27T15:04:33.703871Z"
        },
        "papermill": {
          "duration": 1.235466,
          "end_time": "2021-09-27T15:04:33.704879",
          "exception": false,
          "start_time": "2021-09-27T15:04:32.469413",
          "status": "completed"
        },
        "tags": [],
        "id": "ad2a1858"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/train.csv')\n",
        "test_data = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/test.csv')\n",
        "\n",
        "external_data1 = pd.read_csv('../input/mlqa-hindi-processed/mlqa_hindi.csv')\n",
        "external_data2 = pd.read_csv('../input/mlqa-hindi-processed/xquad.csv')\n",
        "train_data = pd.concat([train_data,external_data1,external_data2]).reset_index(drop=True)\n",
        "\n",
        "sample = pd.read_csv('../input/chaii-hindi-and-tamil-question-answering/sample_submission.csv')\n",
        "\n",
        "train_data = pd.concat([train_data.query('language== \"tamil\"'),train_data.query('language == \"hindi\"').sample(n=368)]).reset_index(drop=True)\n",
        "\n",
        "train_data['Fold'] = -1\n",
        "kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
        "for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=train_data['language'])):\n",
        "    train_data.loc[valid_idx,'Fold'] = k\n",
        "\n",
        "def convert_answers(r):\n",
        "    return {'answer_start': [r[0]], 'text': [r[1]]}\n",
        "\n",
        "train_data['answers'] = train_data[['answer_start', 'answer_text']].apply(convert_answers, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2772567c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:33.739029Z",
          "iopub.status.busy": "2021-09-27T15:04:33.738289Z",
          "iopub.status.idle": "2021-09-27T15:04:33.742107Z",
          "shell.execute_reply": "2021-09-27T15:04:33.742552Z"
        },
        "papermill": {
          "duration": 0.026621,
          "end_time": "2021-09-27T15:04:33.742682",
          "exception": false,
          "start_time": "2021-09-27T15:04:33.716061",
          "status": "completed"
        },
        "tags": [],
        "id": "2772567c",
        "outputId": "1e01b678-26db-4474-bd98-9198e13de99b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7729, 8),\n",
              " hindi    7361\n",
              " tamil     368\n",
              " Name: language, dtype: int64)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape,train_data.language.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19f35087",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:33.770371Z",
          "iopub.status.busy": "2021-09-27T15:04:33.769886Z",
          "iopub.status.idle": "2021-09-27T15:04:33.789261Z",
          "shell.execute_reply": "2021-09-27T15:04:33.789673Z"
        },
        "papermill": {
          "duration": 0.035061,
          "end_time": "2021-09-27T15:04:33.789801",
          "exception": false,
          "start_time": "2021-09-27T15:04:33.754740",
          "status": "completed"
        },
        "tags": [],
        "id": "19f35087",
        "outputId": "7a7d6c92-2ac2-4ff7-e72e-4b770a924db2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>language</th>\n",
              "      <th>Fold</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>903deec17</td>\n",
              "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
              "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
              "      <td>206</td>\n",
              "      <td>53</td>\n",
              "      <td>tamil</td>\n",
              "      <td>4</td>\n",
              "      <td>{'answer_start': [53], 'text': ['206']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d9841668c</td>\n",
              "      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n",
              "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
              "      <td>காசுமீரில்</td>\n",
              "      <td>2358</td>\n",
              "      <td>tamil</td>\n",
              "      <td>0</td>\n",
              "      <td>{'answer_start': [2358], 'text': ['காசுமீரில்']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29d154b56</td>\n",
              "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
              "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
              "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
              "      <td>0</td>\n",
              "      <td>tamil</td>\n",
              "      <td>1</td>\n",
              "      <td>{'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41660850a</td>\n",
              "      <td>குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...</td>\n",
              "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
              "      <td>தாலாட்டு</td>\n",
              "      <td>68</td>\n",
              "      <td>tamil</td>\n",
              "      <td>1</td>\n",
              "      <td>{'answer_start': [68], 'text': ['தாலாட்டு']}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b29c82c22</td>\n",
              "      <td>சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...</td>\n",
              "      <td>பூமியின் அருகில் உள்ள விண்மீன் எது?</td>\n",
              "      <td>சூரியனும்</td>\n",
              "      <td>585</td>\n",
              "      <td>tamil</td>\n",
              "      <td>0</td>\n",
              "      <td>{'answer_start': [585], 'text': ['சூரியனும்']}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                            context  \\\n",
              "0  903deec17  ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   \n",
              "1  d9841668c  காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...   \n",
              "2  29d154b56  சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   \n",
              "3  41660850a  குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...   \n",
              "4  b29c82c22  சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...   \n",
              "\n",
              "                                            question  \\\n",
              "0               மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
              "1                         காளிதாசன் எங்கு பிறந்தார்?   \n",
              "2                   பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
              "3  தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
              "4                பூமியின் அருகில் உள்ள விண்மீன் எது?   \n",
              "\n",
              "                  answer_text  answer_start language  Fold  \\\n",
              "0                         206            53    tamil     4   \n",
              "1                  காசுமீரில்          2358    tamil     0   \n",
              "2  சர் அலெக்ஸாண்டர் ஃபிளெமிங்             0    tamil     1   \n",
              "3                    தாலாட்டு            68    tamil     1   \n",
              "4                   சூரியனும்           585    tamil     0   \n",
              "\n",
              "                                             answers  \n",
              "0            {'answer_start': [53], 'text': ['206']}  \n",
              "1   {'answer_start': [2358], 'text': ['காசுமீரில்']}  \n",
              "2  {'answer_start': [0], 'text': ['சர் அலெக்ஸாண்ட...  \n",
              "3       {'answer_start': [68], 'text': ['தாலாட்டு']}  \n",
              "4     {'answer_start': [585], 'text': ['சூரியனும்']}  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Предобработка данных"
      ],
      "metadata": {
        "id": "n1VBbFPxWeET"
      },
      "id": "n1VBbFPxWeET"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c52fac1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:33.826052Z",
          "iopub.status.busy": "2021-09-27T15:04:33.825347Z",
          "iopub.status.idle": "2021-09-27T15:04:33.828481Z",
          "shell.execute_reply": "2021-09-27T15:04:33.828924Z"
        },
        "papermill": {
          "duration": 0.026965,
          "end_time": "2021-09-27T15:04:33.829050",
          "exception": false,
          "start_time": "2021-09-27T15:04:33.802085",
          "status": "completed"
        },
        "tags": [],
        "id": "6c52fac1"
      },
      "outputs": [],
      "source": [
        "def prepare_train_features(examples, tokenizer, pad_on_right, max_length, doc_stride):\n",
        "    examples['question'] = [q.lstrip() for q in examples['question']]\n",
        "    \n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\")\n",
        "    \n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    \n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "    \n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "                token_start_index += 1\n",
        "\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "                token_end_index -= 1\n",
        "\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дообучение модели"
      ],
      "metadata": {
        "id": "U1w41LVrWiQt"
      },
      "id": "U1w41LVrWiQt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce8d599c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:33.864185Z",
          "iopub.status.busy": "2021-09-27T15:04:33.863499Z",
          "iopub.status.idle": "2021-09-27T15:04:33.866766Z",
          "shell.execute_reply": "2021-09-27T15:04:33.866356Z"
        },
        "papermill": {
          "duration": 0.025543,
          "end_time": "2021-09-27T15:04:33.866869",
          "exception": false,
          "start_time": "2021-09-27T15:04:33.841326",
          "status": "completed"
        },
        "tags": [],
        "id": "ce8d599c"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,model_name):\n",
        "        super(Model,self).__init__()\n",
        "        self.config = AutoConfig.from_pretrained(model_name)\n",
        "        self.roberta = AutoModel.from_pretrained(model_name,config=config)\n",
        "        self.roberta.pooler = nn.Identity()\n",
        "        self.linear = nn.Linear(self.config.hidden_size,2)\n",
        "        \n",
        "    def loss_fn(self,start_logits,end_logits,start_positions,end_positions):\n",
        "        if len(start_positions.size()) > 1:\n",
        "            start_positions = start_positions.squeeze(-1)\n",
        "        if len(end_positions.size()) > 1:\n",
        "            end_positions = end_positions.squeeze(-1)\n",
        "\n",
        "        ignored_index = start_logits.size(1)\n",
        "        start_positions = start_positions.clamp(0, ignored_index)\n",
        "        end_positions = end_positions.clamp(0, ignored_index)\n",
        "        loss_fct = nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
        "        start_loss = loss_fct(start_logits, start_positions)\n",
        "        end_loss = loss_fct(end_logits, end_positions)\n",
        "        total_loss = 0.75 * start_loss + 0.25 * end_loss \n",
        "        return total_loss\n",
        "    \n",
        "    def forward(self,**xb):\n",
        "        x = self.roberta(input_ids=xb['input_ids'],attention_mask=xb['attention_mask'])[0]\n",
        "        x = self.linear(x)\n",
        "        \n",
        "        start_logits,end_logits = x.split(1,dim=-1)\n",
        "        start_logits,end_logits = start_logits.squeeze(-1).contiguous(),end_logits.squeeze(-1).contiguous()\n",
        "        start_positions,end_positions = xb['start_positions'],xb['end_positions']\n",
        "        \n",
        "        loss = None\n",
        "        if start_positions is not None and end_positions is not None:\n",
        "            loss = self.loss_fn(start_logits, end_logits, start_positions, end_positions)\n",
        "            \n",
        "        return (start_logits,end_logits),loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71b57426",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:33.896974Z",
          "iopub.status.busy": "2021-09-27T15:04:33.896320Z",
          "iopub.status.idle": "2021-09-27T15:04:33.899275Z",
          "shell.execute_reply": "2021-09-27T15:04:33.899651Z"
        },
        "papermill": {
          "duration": 0.020994,
          "end_time": "2021-09-27T15:04:33.899768",
          "exception": false,
          "start_time": "2021-09-27T15:04:33.878774",
          "status": "completed"
        },
        "tags": [],
        "id": "71b57426"
      },
      "outputs": [],
      "source": [
        "class ChaiiDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):            \n",
        "        return {\"input_ids\": torch.tensor(self.data[idx][\"input_ids\"], dtype=torch.long),\n",
        "                \"attention_mask\": torch.tensor(self.data[idx][\"attention_mask\"], dtype=torch.long),\n",
        "                \"start_positions\":torch.tensor(self.data[idx][\"start_positions\"],dtype=torch.long),\n",
        "                \"end_positions\":torch.tensor(self.data[idx][\"end_positions\"],dtype=torch.long) }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Запуск обучения"
      ],
      "metadata": {
        "id": "NZFvm2z_Wobk"
      },
      "id": "NZFvm2z_Wobk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6cc78dc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:33.944588Z",
          "iopub.status.busy": "2021-09-27T15:04:33.927208Z",
          "iopub.status.idle": "2021-09-27T15:04:33.946572Z",
          "shell.execute_reply": "2021-09-27T15:04:33.946987Z"
        },
        "papermill": {
          "duration": 0.034781,
          "end_time": "2021-09-27T15:04:33.947100",
          "exception": false,
          "start_time": "2021-09-27T15:04:33.912319",
          "status": "completed"
        },
        "tags": [],
        "id": "f6cc78dc"
      },
      "outputs": [],
      "source": [
        "def run(fold):\n",
        "    \n",
        "    def evaluate(model,valid_loader):\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for i, inputs in enumerate(tqdm(valid_loader)):\n",
        "                inputs = {key:val.reshape(val.shape[0],-1) for key,val in inputs.items()}\n",
        "                outputs = model(**inputs)\n",
        "                loss = outputs[1]\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "        valid_loss /= len(valid_loader)\n",
        "        return valid_loss\n",
        "        \n",
        "    def train_and_evaluate_loop(train_loader,valid_loader,model,optimizer,\n",
        "                                epoch,fold,best_loss,lr_scheduler=None):\n",
        "        train_loss = 0\n",
        "        for i, inputs in enumerate(tqdm(train_loader)):\n",
        "            optimizer.zero_grad()\n",
        "            model.train()\n",
        "            inputs = {key:val.reshape(val.shape[0],-1) for key,val in inputs.items()}\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[1]\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            \n",
        "            if lr_scheduler:\n",
        "                lr_scheduler.step()\n",
        "        \n",
        "        train_loss /= len(train_loader)\n",
        "        valid_loss = evaluate(model,valid_loader) \n",
        "\n",
        "        if valid_loss <= best_loss:\n",
        "            print(f\"Epoch:{epoch} |Train Loss:{train_loss}|Valid Loss:{valid_loss}\")\n",
        "            print(f\"{g_}Loss Decreased from {best_loss} to {valid_loss}{sr_}\")\n",
        "\n",
        "            best_loss = valid_loss\n",
        "            torch.save(model.state_dict(),f'./model{fold}/model{fold}.bin')\n",
        "            tokenizer.save_pretrained(f'./model{fold}')\n",
        "                    \n",
        "        return best_loss\n",
        "        \n",
        "    accelerator = Accelerator()\n",
        "    print(f\"{accelerator.device} is used\")\n",
        "    \n",
        "    x_train,x_valid = train_data.query(f\"Fold != {fold}\"),train_data.query(f\"Fold == {fold}\")\n",
        "        \n",
        "    model = Model(config['model_path'])\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config['model_path'])\n",
        "    pad_on_right = tokenizer.padding_side == 'right'\n",
        "    \n",
        "    train_dataset = Dataset.from_pandas(x_train)\n",
        "    train_features = train_dataset.map(\n",
        "                    partial(\n",
        "                        prepare_train_features, \n",
        "                        tokenizer=tokenizer,\n",
        "                        pad_on_right=pad_on_right, \n",
        "                        max_length=config['max_length'],\n",
        "                        doc_stride=config['doc_stride']\n",
        "                    ),\n",
        "                    batched=True,\n",
        "                    remove_columns=train_dataset.column_names)\n",
        "        \n",
        "    train_ds = ChaiiDataset(train_features)\n",
        "    train_dl = DataLoader(train_ds,\n",
        "                        batch_size = config[\"batch_size\"],\n",
        "                        num_workers = config['num_workers'],\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True,\n",
        "                        drop_last=True)\n",
        "    \n",
        "\n",
        "    valid_dataset = Dataset.from_pandas(x_valid)\n",
        "    valid_features = valid_dataset.map(\n",
        "                    partial(\n",
        "                        prepare_train_features, \n",
        "                        tokenizer=tokenizer,\n",
        "                        pad_on_right=pad_on_right, \n",
        "                        max_length=config['max_length'],\n",
        "                        doc_stride=config['doc_stride']\n",
        "                    ),\n",
        "                    batched=True,\n",
        "                    remove_columns=train_dataset.column_names)\n",
        "        \n",
        "    valid_ds = ChaiiDataset(valid_features)\n",
        "    valid_dl = DataLoader(valid_ds,\n",
        "                        batch_size = config[\"batch_size\"],\n",
        "                        num_workers = config['num_workers'],\n",
        "                        shuffle=False,\n",
        "                        pin_memory=True,\n",
        "                        drop_last=False)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(),lr=config['lr'],weight_decay=config['wd'])    \n",
        "    lr_scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
        "                                                   num_warmup_steps=0,\n",
        "                                                   num_training_steps= config['epochs'] * len(train_dl))\n",
        "\n",
        "    model,train_dl,valid_dl,optimizer,lr_scheduler = accelerator.prepare(model,train_dl,valid_dl,optimizer,lr_scheduler)\n",
        "\n",
        "    print(f\"Fold: {fold}\")\n",
        "    best_loss = 9999\n",
        "    start_time = time.time()\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        print(f\"Epoch Started:{epoch}\")\n",
        "        best_loss = train_and_evaluate_loop(train_dl,valid_dl,model,optimizer,epoch,fold,best_loss,lr_scheduler)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        print(f\"{m_}Time taken by epoch {epoch} is {end_time-start_time:.2f}s{sr_}\")\n",
        "        start_time = end_time\n",
        "        \n",
        "    return best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35622a87",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T15:04:34.032008Z",
          "iopub.status.busy": "2021-09-27T15:04:34.029759Z",
          "iopub.status.idle": "2021-09-27T19:26:36.313019Z",
          "shell.execute_reply": "2021-09-27T19:26:36.313781Z"
        },
        "papermill": {
          "duration": 15722.354364,
          "end_time": "2021-09-27T19:26:36.314025",
          "exception": false,
          "start_time": "2021-09-27T15:04:33.959661",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "658922b25ea44788a072b2e5e5661212",
            "43ed6a4319da46e394491b024998d096",
            "37c47bf4f27948388b7f5a0c506842c9",
            "d58fb167678d44849ffd7878a8a666b1",
            "5c251049cf4143628fdc5e60c833ac40",
            "ddc2e3ef151a427e8f72e337bee97ffe",
            "bbc2aaacfa3743c699d15ce33d81f86c",
            "2a3f2f5891c64bf288193b8d537b2bb1",
            "1a93405f7b0242f89097642a54fa55b5",
            "0fce99d2caae4ac8ae6e18503666b994",
            "b3d66ac529114882874b74ba10e19eac",
            "056b05a4274d4a87b9447f0c13284e3a",
            "639c48fc66e84ed096c5ff5e55bd4315",
            "761f9e7a70914c2e9e543a65110c90a0",
            "9692636071584ad0945dc83fe1ddaf84",
            "b88b2be009354ec3bb958b6555707cf7",
            "f64f7e4c5abc49f1bd649a55924ca9b2",
            "ccbf6858acaa47749309182e47d2c412",
            "97473e9b096e4dfd904775404ebd22f3",
            "377847a799f849d390f09328c6b166c8"
          ]
        },
        "id": "35622a87",
        "outputId": "e49c19d2-b3ea-42ca-ca95-571a132e5ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda is used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "658922b25ea44788a072b2e5e5661212",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43ed6a4319da46e394491b024998d096",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold: 0\n",
            "Epoch Started:0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37c47bf4f27948388b7f5a0c506842c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4587.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d58fb167678d44849ffd7878a8a666b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1180.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:0 |Train Loss:0.6577909169391483|Valid Loss:0.5328498437515656\n",
            "\u001b[32mLoss Decreased from 9999 to 0.5328498437515656\u001b[0m\n",
            "\u001b[35mTime taken by epoch 0 is 3067.15s\u001b[0m\n",
            "cuda is used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c251049cf4143628fdc5e60c833ac40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddc2e3ef151a427e8f72e337bee97ffe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold: 1\n",
            "Epoch Started:0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbc2aaacfa3743c699d15ce33d81f86c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4574.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a3f2f5891c64bf288193b8d537b2bb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1194.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:0 |Train Loss:0.6679888667178521|Valid Loss:0.5453699062046223\n",
            "\u001b[32mLoss Decreased from 9999 to 0.5453699062046223\u001b[0m\n",
            "\u001b[35mTime taken by epoch 0 is 3061.06s\u001b[0m\n",
            "cuda is used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a93405f7b0242f89097642a54fa55b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fce99d2caae4ac8ae6e18503666b994",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold: 2\n",
            "Epoch Started:0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3d66ac529114882874b74ba10e19eac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4647.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "056b05a4274d4a87b9447f0c13284e3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1120.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:0 |Train Loss:0.6552185215104067|Valid Loss:0.5701640377656596\n",
            "\u001b[32mLoss Decreased from 9999 to 0.5701640377656596\u001b[0m\n",
            "\u001b[35mTime taken by epoch 0 is 3096.70s\u001b[0m\n",
            "cuda is used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "639c48fc66e84ed096c5ff5e55bd4315",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "761f9e7a70914c2e9e543a65110c90a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold: 3\n",
            "Epoch Started:0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9692636071584ad0945dc83fe1ddaf84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4608.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b88b2be009354ec3bb958b6555707cf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1160.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:0 |Train Loss:0.6655369259998325|Valid Loss:0.5339459364226435\n",
            "\u001b[32mLoss Decreased from 9999 to 0.5339459364226435\u001b[0m\n",
            "\u001b[35mTime taken by epoch 0 is 3077.57s\u001b[0m\n",
            "cuda is used\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f64f7e4c5abc49f1bd649a55924ca9b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccbf6858acaa47749309182e47d2c412",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold: 4\n",
            "Epoch Started:0\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97473e9b096e4dfd904775404ebd22f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4651.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "377847a799f849d390f09328c6b166c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1116.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:0 |Train Loss:0.650711741827575|Valid Loss:0.5566816597807526\n",
            "\u001b[32mLoss Decreased from 9999 to 0.5566816597807526\u001b[0m\n",
            "\u001b[35mTime taken by epoch 0 is 3097.21s\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "best_loss_per_fold = [run(f) for f in range(config['nfolds'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dc6b7dd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-27T19:26:36.666449Z",
          "iopub.status.busy": "2021-09-27T19:26:36.664599Z",
          "iopub.status.idle": "2021-09-27T19:26:36.684845Z",
          "shell.execute_reply": "2021-09-27T19:26:36.685493Z"
        },
        "papermill": {
          "duration": 0.121276,
          "end_time": "2021-09-27T19:26:36.685731",
          "exception": false,
          "start_time": "2021-09-27T19:26:36.564455",
          "status": "completed"
        },
        "tags": [],
        "id": "5dc6b7dd",
        "outputId": "db7a66ac-0c5e-4192-9b8b-a3bb0f5cea29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.5328498437515656, 0.5453699062046223, 0.5701640377656596, 0.5339459364226435, 0.5566816597807526]\n",
            "0.5478022767850488\n"
          ]
        }
      ],
      "source": [
        "print(best_loss_per_fold)\n",
        "print(np.mean(best_loss_per_fold))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Получение предсказаний"
      ],
      "metadata": {
        "id": "2m1Kh3N0WsQo"
      },
      "id": "2m1Kh3N0WsQo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0618789e",
      "metadata": {
        "papermill": {
          "duration": 0.061468,
          "end_time": "2021-09-27T19:26:36.815361",
          "exception": false,
          "start_time": "2021-09-27T19:26:36.753893",
          "status": "completed"
        },
        "tags": [],
        "id": "0618789e"
      },
      "outputs": [],
      "source": [
        "def get_prediction(df,model_paths,device='cuda'):\n",
        "    start_logits = list()\n",
        "    end_logits = list()\n",
        "    \n",
        "    for path,model_name in model_paths:\n",
        "        model = Model(model_name)\n",
        "        model.eval()\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        pad_on_right = tokenizer.padding_side == 'right'\n",
        "\n",
        "        for f in range(config['nfolds']):\n",
        "            model.load_state_dict(torch.load(path.format(f),map_location=device))\n",
        "            model.to(device)\n",
        "            model.eval()\n",
        "\n",
        "            test_dataset = Dataset.from_pandas(df)\n",
        "            test_features = test_dataset.map(\n",
        "                            partial(\n",
        "                                prepare_validation_features, \n",
        "                                tokenizer=tokenizer,\n",
        "                                pad_on_right=pad_on_right, \n",
        "                                max_length=config['max_length'],\n",
        "                                doc_stride=config['doc_stride']\n",
        "                            ),\n",
        "                            batched=True,\n",
        "                            remove_columns=test_dataset.column_names)\n",
        "\n",
        "            test_feats_small = test_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\n",
        "\n",
        "            test_ds = ChaiiDataset(test_feats_small)\n",
        "            test_dl = DataLoader(test_ds,\n",
        "                                batch_size = config[\"batch_size\"],\n",
        "                                num_workers = config['num_workers'],\n",
        "                                shuffle=False,\n",
        "                                pin_memory=True,\n",
        "                                drop_last=False)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred = list()\n",
        "                start_logit = list()\n",
        "                end_logit = list()\n",
        "                for i, inputs in enumerate(test_dl):\n",
        "                    inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
        "                    outputs = model(**inputs)\n",
        "                    start = outputs[0].detach().cpu().numpy().tolist()\n",
        "                    end = outputs[1].detach().cpu().numpy().tolist()\n",
        "                    start_logit.extend(start)\n",
        "                    end_logit.extend(end)\n",
        "\n",
        "            start_logits.append(start_logit)\n",
        "            end_logits.append(end_logit)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    start_logits, end_logits = np.mean(start_logits,axis=0), np.mean(end_logits,axis=0)\n",
        "\n",
        "    fin_preds = postprocess_qa_predictions(test_dataset, tokenizer, test_features, (start_logits, end_logits))\n",
        "    return fin_preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_paths = [\n",
        "    ('../input/chaii-pytorch-xlmroberta-large/model{0}/model{0}.bin','../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2'),\n",
        "]"
      ],
      "metadata": {
        "id": "Pvt5uKrcB0se"
      },
      "id": "Pvt5uKrcB0se",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-02T08:42:41.024643Z",
          "iopub.status.busy": "2021-10-02T08:42:41.024112Z",
          "iopub.status.idle": "2021-10-02T08:45:04.473682Z",
          "shell.execute_reply": "2021-10-02T08:45:04.472626Z",
          "shell.execute_reply.started": "2021-09-18T07:00:07.701345Z"
        },
        "papermill": {
          "duration": 143.464402,
          "end_time": "2021-10-02T08:45:04.473853",
          "exception": false,
          "start_time": "2021-10-02T08:42:41.009451",
          "status": "completed"
        },
        "tags": [],
        "id": "f4f9708a",
        "outputId": "662cb6f3-4caa-4034-da7d-9fe446d6744c",
        "colab": {
          "referenced_widgets": [
            "a30a0be1c48f4c58a6e5572fb3c5c9c3",
            "68884f31a2f84a8fa6e84c9345f8b8a2",
            "9989288af5b64bf184a2216a5dd9a0bd",
            "2f0c5d5ccd944fa3aece8ebd5e3caa04",
            "435e8d22c6b1454792606c84a45a2708",
            "366af78779f542719fb7cea39911a3fd",
            "1fb12c86599a4a2d95bab3ee7e612bd7",
            "22ea127be06d48e6ac77abcea53850e3",
            "b8da99fb91ca461993c9f9d9a2e12110",
            "f435b1e8b81141879477aa4f7b5dd5ed"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 were not used when initializing XLMRobertaModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ../input/xlm-roberta-squad2/deepset/xlm-roberta-large-squad2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a30a0be1c48f4c58a6e5572fb3c5c9c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68884f31a2f84a8fa6e84c9345f8b8a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9989288af5b64bf184a2216a5dd9a0bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f0c5d5ccd944fa3aece8ebd5e3caa04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "435e8d22c6b1454792606c84a45a2708",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "366af78779f542719fb7cea39911a3fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fb12c86599a4a2d95bab3ee7e612bd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22ea127be06d48e6ac77abcea53850e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8da99fb91ca461993c9f9d9a2e12110",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f435b1e8b81141879477aa4f7b5dd5ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=67.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Post-processing 5 example predictions split into 67 features.\n"
          ]
        }
      ],
      "source": [
        "predictions = get_prediction(test_data,model_paths)"
      ],
      "id": "f4f9708a"
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['PredictionString'] = test_data['id'].map(predictions)"
      ],
      "metadata": {
        "id": "oIt1LmDTB3Ff"
      },
      "id": "oIt1LmDTB3Ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_starts = [\".\", \",\", \"(\", \")\", \"-\", \"–\",  \",\", \";\"]\n",
        "bad_endings = [\"...\", \"-\", \"(\", \")\", \"–\", \",\", \";\"]\n",
        "\n",
        "tamil_ad = \"கி.பி\"\n",
        "tamil_bc = \"கி.மு\"\n",
        "tamil_km = \"கி.மீ\"\n",
        "hindi_ad = \"ई\"\n",
        "hindi_bc = \"ई.पू\"\n",
        "\n",
        "cleaned_preds = []\n",
        "for pred, context in test_data[[\"PredictionString\", \"context\"]].to_numpy():\n",
        "    if pred == \"\":\n",
        "        cleaned_preds.append(pred)\n",
        "        continue\n",
        "    while any([pred.startswith(y) for y in bad_starts]):\n",
        "        pred = pred[1:]\n",
        "    while any([pred.endswith(y) for y in bad_endings]):\n",
        "        if pred.endswith(\"...\"):\n",
        "            pred = pred[:-3]\n",
        "        else:\n",
        "            pred = pred[:-1]\n",
        "    \n",
        "    if any([pred.endswith(tamil_ad), pred.endswith(tamil_bc), pred.endswith(tamil_km), pred.endswith(hindi_ad), pred.endswith(hindi_bc)]) and pred+\".\" in context:\n",
        "        pred = pred+\".\"\n",
        "\n",
        "    cleaned_preds.append(pred)\n",
        "\n",
        "test_data[\"PredictionString\"] = cleaned_preds"
      ],
      "metadata": {
        "id": "2P7fpldIB3IN"
      },
      "id": "2P7fpldIB3IN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[['id', 'PredictionString']].to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "2XVgdUfgB3Kn"
      },
      "id": "2XVgdUfgB3Kn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 15760.857044,
      "end_time": "2021-09-27T19:26:40.757855",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-09-27T15:03:59.900811",
      "version": "2.3.3"
    },
    "colab": {
      "name": "chaii-competition.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}